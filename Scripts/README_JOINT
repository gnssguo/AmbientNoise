

Workflow for joint inversion of RFs and phase velocities

Receiver Functions:

> Download data for the stations and timeframe of interest. Tomo_Get_Prep.py is currently being used for this
Instrument correct for velocity.
> Run the code /home/rmartinshort/Documents/Berkeley/funclab/process_for_funclab.py, giving the name of the data downloaded. This will do
preprocessing and arrange the data into a format that FuncLab can read
> Run FuncLab in a matlab session. Link the data that we've just processed and a newly created 'project directory' where the RFs will be put
> Select 'Compute RFs' and set the parameters you want to use (defaults seem to work)
> Funclab will compute the RFs and put them in a directory called 'RAWDATA' within in the project directory you specfied
> This may take some time
> Once its done, choose 'add-ons'/'stack backazimuth and ray param' and stack the primary RFs with parameters of your choice. Use the plot
tool to see the distribution of RFs

Surface wave dataset:

> You should have a .db file from the surface wave, ant or joint workflows. We will extract phase velocities from this at each station location and
put this data in a structure that can be interpreted by the CPS joint96 workflow
> Run /home/rmartinshort/Documents/Berkeley/Ambient_Noise/AmbientNoise/Scripts/Depth_Invert/Station_grid/get_stations.py. This will get the coordinates of the station locations
where you want to extract phase velocities from the database. Append -addocean to get 'ghost stations' in the ocean. These won't have receiver functions, but the code will invert surface
waves for their Vs profiles
> Run /home/rmartinshort/Documents/Berkeley/Ambient_Noise/AmbientNoise/Scripts/Depth_Invert/Station_grid/dispersion_db_to_hermmann_input.m. This will generate the station directories and fill
them with files called nnall.dsp
> Make a file called "Alaska_station_names.txt", containing the names of all the directory names in the hermann dir where the inversion will be run
> You can now run a surf96 inversion (surface wave only). Use a code like /home/rmartinshort/Documents/Berkeley/Ambient_Noise/AmbientNoise/Scripts/Depth_Invert/CPS_invert_ph_ALL_750_md_stations.sh
and give the path to the dataset

Adding RFs to the surface wave dataset:

> Use /home/rmartinshort/Documents/Berkeley/Ambient_Noise/AmbientNoise/Scripts/Depth_Invert/Joint/Prep_for_joint_inversion.py. Specify the RF directory, the surface wave directory and the directory
where the joint project is going to be placed. This code will copy the relevant RFs in to their station directories and generate the input files needed for joint96
> You're now ready to run a joint96 inversion. Use the code /home/rmartinshort/Documents/Berkeley/Ambient_Noise/AmbientNoise/Scripts/Depth_Invert/CPS_invert_JOINT_stations.sh to do this
> Direct the output to a log file - this will be used to do the QC
> Once its done, edit the code /home/rmartinshort/Documents/Berkeley/Ambient_Noise/AmbientNoise/Scripts/Depth_Invert/Joint/Parse_RF_inversion_log.py to point to the logfile that just got created
You can also specify the QC criteria (e.g reject all fits worse than 70%)
> This code will move RFs that do not fit the QC criteria to a separate directory, enabling the inversion to be run again
> Use the CPS_invert_JOINT code to run the inversion again, using the QC'd RFs

Combining and plottng:

> Once the second round of inversions are done, use /home/rmartinshort/Documents/Berkeley/Ambient_Noise/AmbientNoise/Scripts/Depth_Invert/Joint/Generate_station_database_joint.py to extract the
end.mod profiles and put them in a database. You will need to specify the inversion directory and the file containing the coordinates of each station. This will make a file called 'alaskastations.3d.mod'
> Now, interpolate and smooth the model: Run interpolate_alaska_stations.m with the .mod file we just made specified, in addition to the interpolation parameters. This will make a file appended by
smooth.mod
> Use the slicing and plotting scripts to investigate this file
